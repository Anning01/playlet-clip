"""Gradio application main entry."""

import asyncio
from pathlib import Path
from typing import Generator

import gradio as gr
from loguru import logger

from playlet_clip.core.config import Settings, get_settings
from playlet_clip.core.pipeline import PlayletPipeline
from playlet_clip.models.task import TaskProgress, TaskStatus
from playlet_clip.services.tts import TTSService


def _format_error(title: str, detail: str | None) -> str:
    """Format error message as HTML for display."""
    import html

    title_escaped = html.escape(str(title)) if title else "æœªçŸ¥é”™è¯¯"
    detail_escaped = html.escape(str(detail)) if detail else ""

    return f"""
    <div class="error-box">
        <h4 style="margin: 0 0 8px 0; color: #dc2626;">âŒ {title_escaped}</h4>
        <pre style="margin: 0; color: #7f1d1d;">{detail_escaped}</pre>
    </div>
    """


def create_app(settings: Settings | None = None) -> gr.Blocks:
    """
    Create the Gradio application.

    Args:
        settings: Application settings (optional, loads default if not provided)

    Returns:
        Gradio Blocks application
    """
    if settings is None:
        settings = get_settings()

    # Initialize pipeline
    pipeline = PlayletPipeline(settings)

    # Get available styles
    style_choices = [s.name for s in settings.styles]

    # Get available voices
    voice_choices = TTSService.PRESET_VOICES

    # Custom CSS
    css = """
    .progress-container {
        margin: 10px 0;
    }
    .video-container video {
        max-height: 45vh !important;
        width: 100%;
        object-fit: contain;
    }
    .error-box {
        background-color: #fee2e2;
        border: 1px solid #ef4444;
        border-radius: 8px;
        padding: 12px;
        margin-top: 10px;
    }
    .error-box pre {
        white-space: pre-wrap;
        word-wrap: break-word;
        font-size: 12px;
        max-height: 300px;
        overflow-y: auto;
    }
    """

    with gr.Blocks(
        title="Playlet-Clip - AIçŸ­å‰§è‡ªåŠ¨å‰ªè¾‘",
        theme=gr.themes.Soft(),
        css=css,
    ) as app:
        # Header
        gr.Markdown(
            """
            # ğŸ¬ Playlet-Clip
            ### AIé©±åŠ¨çš„çŸ­å‰§è‡ªåŠ¨åŒ–å‰ªè¾‘å·¥å…·

            ä¸Šä¼ è§†é¢‘ â†’ ASRæå–å­—å¹• â†’ AIç”Ÿæˆè§£è¯´ â†’ TTSåˆæˆè¯­éŸ³ â†’ è‡ªåŠ¨å‰ªè¾‘æˆç‰‡
            """
        )

        with gr.Tabs():
            # Tab 1: Video Processing
            with gr.Tab("è§†é¢‘å¤„ç†", id="process"):
                with gr.Row():
                    # Left column: Input
                    with gr.Column(scale=1):
                        video_input = gr.Video(
                            label="ä¸Šä¼ è§†é¢‘",
                            sources=["upload"],
                            elem_classes=["video-container"],
                        )

                        style_dropdown = gr.Dropdown(
                            choices=style_choices,
                            value=style_choices[0] if style_choices else None,
                            label="è§£è¯´é£æ ¼",
                        )

                        with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                            voice_dropdown = gr.Dropdown(
                                choices=voice_choices,
                                value=settings.tts.default_voice,
                                label="è§£è¯´éŸ³è‰²",
                            )

                            blur_height = gr.Slider(
                                minimum=0,
                                maximum=500,
                                value=settings.video.blur_height,
                                step=5,
                                label="å­—å¹•æ¨¡ç³ŠåŒºåŸŸé«˜åº¦ (åƒç´ )",
                            )

                            blur_y = gr.Slider(
                                minimum=0,
                                maximum=2000,
                                value=settings.video.blur_y,
                                step=10,
                                label="å­—å¹•æ¨¡ç³ŠåŒºåŸŸä½ç½® (åƒç´ )",
                            )

                            subtitle_margin = gr.Slider(
                                minimum=0,
                                maximum=200,
                                value=settings.video.subtitle_margin,
                                step=5,
                                label="å­—å¹•è¾¹è· (åƒç´ )",
                            )

                        # Optional existing subtitles
                        with gr.Accordion("ä½¿ç”¨å·²æœ‰å­—å¹• (å¯é€‰)", open=False):
                            srt_input = gr.File(
                                label="ä¸Šä¼ SRTå­—å¹•æ–‡ä»¶",
                                file_types=[".srt"],
                            )
                            gr.Markdown("*å¦‚æœä¸Šä¼ å­—å¹•æ–‡ä»¶ï¼Œå°†è·³è¿‡ASRè¯­éŸ³è¯†åˆ«æ­¥éª¤*")

                        process_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")

                    # Right column: Output
                    with gr.Column(scale=1):
                        # Progress display
                        progress_text = gr.Textbox(
                            label="å¤„ç†çŠ¶æ€",
                            value="ç­‰å¾…å¼€å§‹...",
                            interactive=False,
                        )
                        progress_bar = gr.Slider(
                            minimum=0,
                            maximum=100,
                            value=0,
                            label="è¿›åº¦",
                            interactive=False,
                        )

                        # Output video
                        output_video = gr.Video(
                            label="å¤„ç†ç»“æœ",
                            elem_classes=["video-container"],
                        )

                        # Download button
                        download_file = gr.File(
                            label="ä¸‹è½½è§†é¢‘",
                            visible=False,
                        )

                        # Error display
                        error_output = gr.HTML(
                            label="é”™è¯¯ä¿¡æ¯",
                            visible=False,
                            elem_classes=["error-box"],
                        )

            # Tab 2: Settings
            with gr.Tab("è®¾ç½®", id="settings"):
                gr.Markdown("### API é…ç½®")

                with gr.Row():
                    api_key_input = gr.Textbox(
                        label="OpenAI API Key",
                        value=settings.llm.api_key[:10] + "..." if settings.llm.api_key else "",
                        type="password",
                        placeholder="sk-...",
                    )

                    base_url_input = gr.Textbox(
                        label="API Base URL",
                        value=settings.llm.base_url,
                        placeholder="https://api.openai.com/v1",
                    )

                model_input = gr.Textbox(
                    label="æ¨¡å‹åç§°",
                    value=settings.llm.model,
                    placeholder="gpt-4o",
                )

                save_settings_btn = gr.Button("ä¿å­˜è®¾ç½®", variant="secondary")
                settings_status = gr.Textbox(
                    label="çŠ¶æ€",
                    value="",
                    interactive=False,
                )

                gr.Markdown("---")
                gr.Markdown("### è§£è¯´é£æ ¼ç®¡ç†")

                styles_display = gr.Dataframe(
                    headers=["åç§°", "æè¿°"],
                    value=[[s.name, s.description] for s in settings.styles],
                    label="å½“å‰é£æ ¼åˆ—è¡¨",
                )

            # Tab 3: Voice Management
            with gr.Tab("éŸ³è‰²ç®¡ç†", id="voices"):
                gr.Markdown("### å¯ç”¨éŸ³è‰²")

                voices_display = gr.Dataframe(
                    headers=["éŸ³è‰²åç§°"],
                    value=[[v] for v in voice_choices],
                    label="é¢„è®¾éŸ³è‰²",
                )

                gr.Markdown("---")
                gr.Markdown("### éŸ³è‰²å…‹éš† (å®éªŒæ€§)")

                with gr.Row():
                    clone_audio = gr.Audio(
                        label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘",
                        type="filepath",
                    )
                    clone_text = gr.Textbox(
                        label="å‚è€ƒéŸ³é¢‘æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­è¯´çš„è¯...",
                    )

                clone_name = gr.Textbox(
                    label="æ–°éŸ³è‰²åç§°",
                    placeholder="æˆ‘çš„è‡ªå®šä¹‰éŸ³è‰²",
                )

                clone_btn = gr.Button("å…‹éš†éŸ³è‰²", variant="secondary")
                clone_status = gr.Textbox(
                    label="å…‹éš†çŠ¶æ€",
                    value="",
                    interactive=False,
                )

            # Tab 4: About
            with gr.Tab("å…³äº", id="about"):
                gr.Markdown(
                    """
                    ## Playlet-Clip v2.0

                    AIé©±åŠ¨çš„çŸ­å‰§è‡ªåŠ¨åŒ–å‰ªè¾‘å·¥å…·

                    ### åŠŸèƒ½ç‰¹ç‚¹
                    - ğŸ¤ **ASRè¯­éŸ³è¯†åˆ«**: ä½¿ç”¨FunASRè‡ªåŠ¨æå–è§†é¢‘å­—å¹•
                    - ğŸ¤– **AIè§£è¯´ç”Ÿæˆ**: ä½¿ç”¨ChatGPTæ ¹æ®å­—å¹•ç”Ÿæˆè§£è¯´æ–‡æ¡ˆ
                    - ğŸ”Š **TTSè¯­éŸ³åˆæˆ**: ä½¿ç”¨CosyVoiceåˆæˆè‡ªç„¶çš„è§£è¯´è¯­éŸ³
                    - ğŸ¬ **è‡ªåŠ¨è§†é¢‘å‰ªè¾‘**: æ™ºèƒ½å‰ªè¾‘åˆæˆæœ€ç»ˆè§†é¢‘

                    ### æŠ€æœ¯æ ˆ
                    - Python 3.10+
                    - FunASR (è¯­éŸ³è¯†åˆ«)
                    - CosyVoice (è¯­éŸ³åˆæˆ)
                    - OpenAI API (è§£è¯´ç”Ÿæˆ)
                    - FFmpeg (è§†é¢‘å¤„ç†)
                    - Gradio (Webç•Œé¢)

                    ### ä½œè€…
                    - anning (anningforchina@gmail.com)

                    ### å¼€æºåè®®
                    MIT License
                    """
                )

        # Event handlers
        async def process_video(
            video_path: str,
            style: str,
            voice: str,
            blur_h: int,
            blur_y_val: int,
            margin: int,
            srt_file: str | None,
        ) -> Generator:
            """Process video with progress updates."""
            if not video_path:
                error_html = _format_error("è¾“å…¥é”™è¯¯", "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                yield (
                    "è¯·å…ˆä¸Šä¼ è§†é¢‘",
                    0,
                    None,
                    gr.update(visible=False),
                    gr.update(visible=True, value=error_html),
                )
                return

            # Update settings with UI values
            settings.video.blur_height = blur_h
            settings.video.blur_y = blur_y_val
            settings.video.subtitle_margin = margin
            settings.tts.default_voice = voice

            video_file = Path(video_path)
            srt_path = Path(srt_file) if srt_file else None

            progress_updates = []

            def progress_callback(progress: TaskProgress):
                progress_updates.append(progress)

            try:
                # Start processing in background
                if srt_path and srt_path.exists():
                    # Use existing subtitles
                    task = pipeline.process_with_existing_subtitles(
                        video_path=video_file,
                        srt_path=srt_path,
                        style=style,
                        progress_callback=progress_callback,
                    )
                else:
                    # Full pipeline with ASR
                    task = pipeline.process(
                        video_path=video_file,
                        style=style,
                        progress_callback=progress_callback,
                    )

                # Create task
                loop = asyncio.get_event_loop()
                future = asyncio.ensure_future(task)

                # Poll for progress updates
                while not future.done():
                    await asyncio.sleep(0.5)

                    if progress_updates:
                        latest = progress_updates[-1]
                        status_text = f"[{latest.status.value}] {latest.message}"
                        yield (
                            status_text,
                            latest.progress,
                            None,
                            gr.update(visible=False),
                            gr.update(visible=False),
                        )

                # Get result
                result = await future

                if result.success:
                    yield (
                        f"âœ… å¤„ç†å®Œæˆ! è€—æ—¶: {result.duration:.1f}ç§’, ç‰‡æ®µæ•°: {result.segments_count}",
                        100,
                        str(result.output_path),
                        gr.update(visible=True, value=str(result.output_path)),
                        gr.update(visible=False),
                    )
                else:
                    error_html = _format_error("å¤„ç†å¤±è´¥", result.error_message)
                    yield (
                        f"âŒ å¤„ç†å¤±è´¥",
                        0,
                        None,
                        gr.update(visible=False),
                        gr.update(visible=True, value=error_html),
                    )

            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                error_html = _format_error(str(e), error_detail)
                logger.exception(f"Processing error: {e}")
                yield (
                    "âŒ å¤„ç†å‡ºé”™",
                    0,
                    None,
                    gr.update(visible=False),
                    gr.update(visible=True, value=error_html),
                )

        def save_api_settings(api_key: str, base_url: str, model: str) -> str:
            """Save API settings."""
            try:
                if api_key and not api_key.endswith("..."):
                    settings.llm.api_key = api_key
                if base_url:
                    settings.llm.base_url = base_url
                if model:
                    settings.llm.model = model

                # Save to config file
                config_path = settings.paths.config_dir / "config.yaml"
                settings.to_yaml(config_path)

                return f"âœ… è®¾ç½®å·²ä¿å­˜åˆ° {config_path}"
            except Exception as e:
                return f"âŒ ä¿å­˜å¤±è´¥: {e}"

        # Connect events
        process_btn.click(
            fn=process_video,
            inputs=[
                video_input,
                style_dropdown,
                voice_dropdown,
                blur_height,
                blur_y,
                subtitle_margin,
                srt_input,
            ],
            outputs=[
                progress_text,
                progress_bar,
                output_video,
                download_file,
                error_output,
            ],
        )

        save_settings_btn.click(
            fn=save_api_settings,
            inputs=[api_key_input, base_url_input, model_input],
            outputs=[settings_status],
        )

    return app


def launch_app(
    settings: Settings | None = None,
    share: bool = False,
    server_name: str = "0.0.0.0",
    server_port: int = 7860,
) -> None:
    """
    Launch the Gradio application.

    Args:
        settings: Application settings
        share: Enable Gradio share link
        server_name: Server host
        server_port: Server port
    """
    if settings is None:
        settings = get_settings()

    app = create_app(settings)

    logger.info(f"Launching Gradio app on {server_name}:{server_port}")

    app.launch(
        server_name=server_name,
        server_port=server_port,
        share=share,
        show_error=True,
    )
